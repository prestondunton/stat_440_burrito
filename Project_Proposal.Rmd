---
title: "Project Proposal: Burrito Cost Analysis"
author: "Preston Dunton, Trevor Overton, Jasmine DeMeyer"
date: '2022-04-12'
output: pdf_document
---

# Ingredient Model Proposal

We would like to use the burrito dataset that Dr. Wilson made available on RStudio Cloud.  One interesting direction of study in this dataset is the cost of burritos.

We can imagine that both the ingredients and the restaurant’s margins contribute to cost.  To analyze these relationships, we would a model similar to:

$\text{Cost} = \beta_0 + \beta_1*\text{hasPork} +\beta_2*\text{hasChicken} +\beta_3*\text{hasCheese} +...$

or 

$\text{Cost}\sim N(\mathbf{X}\boldsymbol{\beta},\sigma^2)$

where $\mathbf{X}_{(n\times p)}=\begin{bmatrix}1 & \text{hasPork}_0 & \text{hasChicken}_0 & \text{hasCheese}_0 & ... \\ 1 & \text{hasPork}_1 & \text{hasChicken}_1 & \text{hasCheese}_1 & ... \\ ... & ... & ... & ... & ...\\1 & \text{hasPork}_n & \text{hasChicken}_n & \text{hasCheese}_n & ...\end{bmatrix}$

$p = \text{Number of ingredients}+1$

$\boldsymbol{\beta}_{(p\times1)}=\begin{bmatrix}\beta_0 \\ \beta_1 \\ ... \\ \beta_p\end{bmatrix}$

$\boldsymbol{\beta}\sim MVN(\mathbf{0},\tau^2\textbf{I})$

$\sigma^2\sim \text{Gamma}(a,b)$

All variables except Cost are indicator variables for the ingredients taking on values 0 and 1.  This model uses Cost as a response variable. It also has parameters that can be interpreted as the marginal cost of ingredients. 

Because Cost should be a positive number, we expect Cost and all the $\boldsymbol\beta$ parameters to be positive.  This means we could model this situation as 

$\text{Cost}\sim \text{TruncatedNormal}(\mathbf{X}\boldsymbol{\beta},\sigma^2)$ where the normal is truncated at $\text{Cost} >= 0$.

$\boldsymbol{\beta}\sim \text{TruncatedMVN}(\mathbf{0},\tau^2\textbf{I})$ where the normal is truncated at $\boldsymbol\beta>=\mathbf{0}$.


## Choosing Priors

Let $\sigma=1.5$, and $\text{E}[\sigma^{2}]=2.25$, this means that $a/b=2.25$.  Let $a/b^2=1$,
this means that $a=2.25^2=5.0625$ and $b=2.25$  This means that we expect  burritos with the same ingredients to vary by $1.50. 

$\boldsymbol{\beta}\sim MVN(\mathbf{0},\tau^2\textbf{I})$

Let $\tau=2$ so that $\tau^2=4$.  This means that we expect the marginal cost of an ingredient to vary by $2.00.


# Restaurant Model Proposal

If we wanted to find more information about individual restaurants, and their effect on cost, we would use a model like

$\text{Cost} = \beta_0 + \beta_1*fromOscars + \beta_2*fromDonatos + \beta_3*fromChipotle +...$

which would follow almost the exact same distributions and definitions as the ingredients model presented above.



# Questions

These models could answer questions like:

* What’s the probability that pork costs more on a burrito than chicken?
* What is the average marginal cost of toppings on a burrito?
* How is cost affected by the restaurant from which the burrito was purchased? 
* Are certain restaurants significantly more expensive than others? 

# Data Inspection

## Loading Data

```{r, include=FALSE}
library(knitr)
```

```{r}
load('./burritodata.Rda')
head(burrito)
```


There are $`r nrow(burrito)`$ observations in this dataset.

Here are the different columns in the dataset:
```{r}
colnames(burrito)
```

## Cost

We are interested in cost.  Let's see if there are any missing cost values, and then look at the distribution of costs.

```{r}
which(is.na(burrito$Cost))
```

There are two observations with `NA` costs.  Lets remove these from the dataset and continue using it.

```{r}
burrito_no_na = burrito[!is.na(burrito$Cost),]
nrow(burrito_no_na)

```

```{r}
hist(burrito_no_na$Cost)

```

Burrito costs appear to be somewhat normally distributed.  This is good for our linear regression models.

## Ingredients

We now should now investigate the ingredients, see if there are any missing values, and then see if any ingredients need to be combined into an "Other" category.


```{r}

ingredient_names = colnames(burrito_no_na)[18:50]
num_burrito_ingredients = c()
for (ingredient in ingredient_names) {
  num_burrito_ingredients = c(num_burrito_ingredients, 
                              sum(burrito_no_na[ingredient]))  
}
ingredient_counts_df = data.frame(ingredient=ingredient_names, 
                                  count=num_burrito_ingredients)

# sort by count
ingredient_counts_df = ingredient_counts_df[order(ingredient_counts_df$count, decreasing=TRUE),] 

kable(ingredient_counts_df, row.names=FALSE)

barplot(ingredient_counts_df$count, ylab='Number of Burritos',
        main='Ingredient Distribution', 
        names.arg=ingredient_counts_df$ingredient, las=2)
```

It looks like there are many ingredients where there are few burritos with them.  These are good ingredients to group into an "Other" type category.  Let's decide a cutoff:

```{r}
kable(ingredient_counts_df[ingredient_counts_df$count < 10,], row.names=FALSE)
```

Just by luck, it looks like all ingredients with more than 10 burritos are quite normal (Avocado, Cilantro, Onion, ...), but all ingredients with fewer than 10 burritos are quite rare (Pineapple, Bell Pepper, Fish, Lobster, ...).  Let's use 10 as our cutoff, and now define some categories to group these ingredients into.

Maybe some groups like this:

* Vegetables = (Pineapple, Bell Pepper, Tomato, Cabbage, Mushroom, Corn, Carrots, Zucchini)
* Breakfast = (Egg, Bacon, Ham)
* Other = (Fish, Taquito, Chille Relleno, Nopales, Sushi, Lobster)

These groups will be turned into new indicator variables that we can use with the other 15 ingredients (Beef through Lettuce).  Note, we might need to change the Breakfast category because it still only adds up to only 6 burritos, not over 10.


## Restaurant Analysis

```{r}

location_counts_df = aggregate(data.frame(count = burrito_no_na$Location), 
                               list(location = burrito_no_na$Location), length)
# sort by count
location_counts_df = location_counts_df[order(location_counts_df$count, decreasing=TRUE),] 

kable(location_counts_df, row.names=FALSE)

barplot(location_counts_df$count, ylab='Number of Burritos', 
        main='Location Distribution', names.arg=location_counts_df$location, las=2)

```

We see that the vast majority of locations in the dataset are only represented less than 5 times.  We could possibly group these by region on a map (e.x. Downtown San Diego, ...) or we might only do analysis on the top restaurants.  We'd have to check that subsetting on the top restaurants reduces the number of ingredients in the analysis however.  Do you have any suggestions? 
