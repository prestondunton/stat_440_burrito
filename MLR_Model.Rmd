---
title: "MLR Model"
author: "Preston Dunton, Trevor Overton, Jasmine DeMeyer"
date: "4/24/2022"
output: pdf_document
---

# Imports and Constants

```{r, warning=FALSE, message=FALSE}
library("tidyverse")
source('./gibbs_util.R')

RANDOM_SEED = 440
```

# Data Loading / Cleaning

```{r setup}
load('./burritodata.Rda')
head(burrito)

# Count Remove NA Cost rows
which(is.na(burrito$Cost))
burrito = burrito[!is.na(burrito$Cost),]
nrow(burrito)


burrito<-burrito%>%mutate(Vegetable=as.logical(Pineapple+Bell_peper+Tomato+
                                                 Cabbage+Mushroom+Corn+
                                                 Carrots+Zucchini))
burrito<-burrito%>%mutate(Breakfast=as.logical(Egg+Bacon+Ham))
burrito<-burrito%>%mutate(Other=as.logical(Fish+Taquito+Chile_relleno+
                                             Nopales+Sushi+Lobster))
burrito<-select(burrito, -c('Pineapple', 'Bell_peper', 'Tomato', 'Cabbage', 
                            'Mushroom', 'Corn', 'Carrots', 'Zucchini', 
                            'Egg', 'Ham', 'Fish', 'Taquito', 'Chile_relleno', 
                            'Nopales', 'Sushi', 'Lobster', 'Bacon'))
burrito<-burrito%>%mutate_at(c('Vegetable','Other','Breakfast'),as.double)
head(burrito)

burrito = burrito %>% mutate(Num_Proteins= Chicken + Beef + Pork + Shrimp + Other + Breakfast)

ingredient_cols = colnames(burrito)[18:36]

ingredient_X = as.matrix(burrito[ingredient_cols])
dim(ingredient_X); head(ingredient_X)

cost_y = burrito$Cost
length(cost_y); head(cost_y)
```

# Model Fit with Gibbs Sampler

```{r gibbs}
set.seed(RANDOM_SEED)

p = ncol(ingredient_X) + 1
tau_2 = 4
prior_sigma = 1.5
a = 1 / (prior_sigma^4)
b = 1 / (prior_sigma^2)

mlr_post_dist = mlr_gibbs(ingredient_X, cost_y, mu=rep(0, p), tau_2, a, b)
mlr_post_dist = mlr_post_dist[5001:1000, ]
summarize_dist(mlr_post_dist, colnames(mlr_post_dist), round_places=2)

```

This model won't work for us because it fits prices to be negative.  Instead, why don't we use a truncated Gibbs sampler.

# Truncated Gibbs
```{r t_gibbs}
set.seed(RANDOM_SEED)

truncated_post_dist<-truncated_gibbs(ingredient_X, cost_y, mu=rep(1, p), 
                                     tau_2, a, b, lb=rep(0,p), ub=rep(Inf,p))
truncated_post_dist = truncated_post_dist[5001:1000, ]

```

# Model Diagnostics

```{r trace_plots}
plot_traces(truncated_post_dist[,1:5], 'Parameter Traces (After Burn In)')
plot_traces(truncated_post_dist[,6:10], 'Parameter Traces (After Burn In)')
plot_traces(truncated_post_dist[,11:15], 'Parameter Traces (After Burn In)')
plot_traces(truncated_post_dist[,16:21], 'Parameter Traces (After Burn In)')
```

```{r acf_plots}
acf_plots(truncated_post_dist[,1:5])
acf_plots(truncated_post_dist[,6:10])
acf_plots(truncated_post_dist[,11:15])
acf_plots(truncated_post_dist[,16:21])
```



```{r summary}
summarize_dist(truncated_post_dist, colnames(truncated_post_dist), round_places=2)
```

# Protein Models

```{r protein subsetting}

num_burritos_no_protein = sum(burrito$Num_Proteins == 0)
num_burritos_no_protein
num_burritos_double_protein = sum(burrito$Num_Proteins == 2)
num_burritos_double_protein

burrito_no_double = burrito[burrito$Num_Proteins != 2, ]
head(burrito_no_double)

burrito_no_double = burrito_no_double %>% mutate(Protein= as.factor(Chicken + 2*Beef + 3*Pork + 4*Shrimp + 5*Other + 6*Breakfast))
head(burrito_no_double)

```

```{r mixed model}
proteins = c('Chicken', 'Beef', 'Pork', 'Shrimp', 'Other', 'Breakfast')
X_proteins = as.matrix(burrito[proteins])
head(X_proteins)

mlr_protein_post_dist = truncated_gibbs(X_proteins, cost_y, mu=rep(1, 7), 
                                     tau_2, a, b, lb=rep(0,7), ub=rep(Inf,7))
mlr_protein_post_dist = mlr_protein_post_dist[5001:1000, ]

plot_traces(mlr_protein_post_dist[,1:4], 'Parameter Traces (After Burn In)')
plot_traces(mlr_protein_post_dist[,5:8], 'Parameter Traces (After Burn In)')
summarize_dist(mlr_protein_post_dist, colnames(mlr_protein_post_dist), round_places=2)
```

# Mixed Model

```{r random intercept}
kappa2 <- mean(1/kappa2inv_keep)
sig2 <- mean(1/sig2inv_keep)
sig <- sqrt(sig2)

df <- data.frame(Kappa2 = kappa2, Sigma2 = sig2, Sigma = sig)
kable(df)

res <- res[5001:10000,]

summarize_dist(res, colnames(res), round_places = 2)
```


# Model Diagnostics

```{r Deviance Information Criterion}
mlr_dist<-dic(x=ingredient_X,beta=mlr_post_dist[,-ncol(mlr_post_dist)],sig2=mlr_post_dist[,ncol(mlr_post_dist)],y=cost_y)
truncated_dist<-dic(x=ingredient_X, beta=truncated_post_dist[,-ncol(truncated_post_dist)],sig2=truncated_post_dist[,ncol(truncated_post_dist)],y=cost_y)
reduced<-dic(x=X_proteins,beta=mlr_protein_post_dist[,-ncol(mlr_protein_post_dist)],sig2=mlr_protein_post_dist[,ncol(mlr_protein_post_dist)],y=cost_y)
mlr_dist
truncated_dist
reduced

```

# Model Interpretations

As the DIC for our reduced truncated model is 44.878, while the standard mlr is -152, and the truncated is -129, the reduced model better explains the variance in our data.


